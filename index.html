<!DOCTYPE html>
<!--
	Dopetrope by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>SpeechPrompt</title>

	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="icon" href="images/power.png" />
</head>

<body class="homepage is-preload">
	<div id="page-wrapper">

		<!-- Header -->
		<section id="header">
			<!-- Logo -->
			<h1><a href="index.html">SpeechPrompt</a></h1>

			<!-- Nav -->
			<nav id="nav">
				<ul>
					<li class="current"><a href="index.html">Overview</a></li>
					<li><a href="speech-prompt-v1.html">SpeechPrompt v1</a></li>
					<li><a href="speech-prompt-v2.html">SpeechPrompt v2</a></li>
					<li><a href="speechgen.html">SpeechGen</a></li>
					<!-- <li><a href="no-sidebar.html">More</a></li> -->
				</ul>
			</nav>

			<!-- Banner -->
			<section id="banner">
				<header>
					<h2>Make Spoken Language Models Versatile!</h2>
					<p style="font-weight: 500">Prompt Tuning for Speech Processing Tasks</p>
					<br />
					<ul class="actions">
						<li><a href="speech-prompt-v1.html" class="button">SpeechPrompt v1</a></li>
						<li><a href="speech-prompt-v2.html" class="button">SpeechPrompt v2</a></li>
						<li><a href="speechgen.html" class="button">SpeechGen</a></li>
					</ul>
				</header>
			</section>

			<!-- News -->
			<section>
				<div class="container">
					<!-- Content -->
					<article class="box post">
						<a href="#" class="image featured"></a>
						<!-- WHY??????-->
						<header>
							<h2>NEWS</h2>
						</header>
						<div id="news">
							<ul>
								<li>[June 2023] SpeechGen paper is available [<a
										href="https://arxiv.org/abs/2306.02207">link</a>] </li>
								<li>[May. 2023] SpeechPrompt v2 code released [<a
										href="https://github.com/ga642381/SpeechPrompt-v2">link</a>]</li>
								<li>[March 2023] SpeechPrompt v2 paper is available. [<a
										href="https://arxiv.org/abs/2303.00733">link</a>] </li>
								<li>[Oct. 2022] Website of SeechPrompt project is borned </li>
								<li>[Oct. 2022] "SpeechPrompt" is an research topic in the <b>JSALT workshop</b> [<a
										href="https://jsalt-2022-ssl.github.io/">website</a>]</li>
								<li>
									[June 2022] SpeechPrompt v1 is accepted at <b>INTERSPEECH 2022</b> [<a
										href="https://arxiv.org/abs/2203.16773">paper</a>] [<a
										href="https://github.com/ga642381/SpeechPrompt">code</a>]
								</li>
								<li>
									[March 2022] SpeechPrompt v1 is available on arXiv [<a
										href="https://arxiv.org/abs/2203.16773">link</a>]
								</li>
							</ul>
						</div>
					</article>
				</div>
			</section>
			<section id="main">
				<div class="container">
					<!-- Content -->
					<article class="box post">
						<img style="margin-bottom: 20px" width=100%
							src="SpeechPrompt-v1-assets/SpeechPrompt_animation.gif" alt="" />
						<header>
							<h2>Introduction</h2>
						</header>
						<section style="line-height: 1.75em; font-size: 22px">
							<p>
								Self-supervised learning (SSL) has revolutionized the field of
								computer vision (CV), natural language processing (NLP), and speech processing.
								By pre-training a model on a large amount of unlabeled data in a self-supervised manner,
								the model can learn universal representations that benefit downstream tasks.
								<br><br>
								However, to utilize these SSL models for downstream tasks, we usually follow the
								"pre-train, fine-tune paradigm". That is, we need to (1) design a downstream model,
								(2)fine-tune the model, and (3) store the parameters of the model. This causes a lot of
								computation and storage costs.
								<br><br>
								On the other hand, the "prompting paradigm" has been widely used in the NLP field.
								By leveraging the pre-trained language model's (LM) knowledge, prompt tuning optimizes a
								limited number of parameters for downstream tasks. Prompt tuning can serve a large
								number of downstream tasks in a unified manner with computation and storage efficiency.

								<br><br>
								However, the prompting paradigm has never been explored in the speech processing before.
								Recently, various spoken language models have been developed , which opens the door to
								apply prompt tuning for speech processing tasks ...
								<br><br>
							</p>

						</section>
					</article>
				</div>
			</section>
		</section>

		<!-- Footer -->
		<section id="footer">
			<div class="container"></div>
		</section>
	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>
</body>

</html>